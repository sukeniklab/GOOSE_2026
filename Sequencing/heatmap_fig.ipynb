{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d88794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b66fae",
   "metadata": {},
   "source": [
    "# Header\n",
    "\n",
    "## sub header\n",
    "\n",
    "plain text here with some ```python``` commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c738c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define custom origin order\n",
    "custom_origin_order = [\n",
    "    \"Os_LEA_or6\", \"syn_LEA_1\", \"Asyn_isoform_5\", \"A0A4D6M434\", \"A0A1U8F7A1\",\n",
    "    \"At2g46140_tile7\", \"TgL_8x\", \"A0A438HAK2\", \"Os_LEA_or4\",\n",
    "    \"CAHS_68135_tile4\", \"Os_LEA_or3__Kappa_up_2_\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3efce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Step 1: Load Dataset ===\n",
    "round_df = pd.read_csv('sequencing_data_all.csv')\n",
    "round_df['Sequence_ID'] = round_df['Sequence_ID'].astype(str).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d43932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 2: Define features ===\n",
    "nardini_cols = [col for col in round_df.columns if col.startswith('nardini_') and (col.endswith('_zscore') or col.endswith('_raw'))]\n",
    "\n",
    "other_features = [\n",
    "    'cider_kappa', 'cider_omega', 'cider_delta', 'cider_length', \n",
    "    'cider_mean_net_charge', 'cider_fraction_neutral',\n",
    "    'sparrow_SCD', 'sparrow_SHD', 'sparrow_complexity',\n",
    "    'sparrow_scaled_rg', 'sparrow_scaled_re', \n",
    "    'sparrow_prefactor', 'sparrow_scaling_exponent', 'sparrow_asphericity'\n",
    "]\n",
    "\n",
    "new_feature_cols = [\n",
    "    'avg_helix_prob', 'avg_beta_prob', 'avg_coil_prob',\n",
    "    'avg_mito_targeting', 'avg_nes', 'avg_nis'\n",
    "]\n",
    "\n",
    "all_features = nardini_cols + other_features + new_feature_cols\n",
    "chem_cols = [col for col in all_features if col in round_df.columns]\n",
    "\n",
    "print(f\"Found {len(nardini_cols)} nardini columns\")\n",
    "print(f\"Total features to analyze: {len(chem_cols)}\")\n",
    "\n",
    "df1 = round_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdea763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 5: Spearman r Filtering ===\n",
    "results = []\n",
    "n_iter = 1000\n",
    "min_n = 6\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for base in custom_origin_order:\n",
    "    base_df = df1[df1['base_origin'] == base].copy()\n",
    "    original_id = f\"original_sequence_-_{base}\"\n",
    "    original_row = df1[df1['Sequence_ID'] == original_id]\n",
    "\n",
    "    if original_row.empty:\n",
    "        print(f\"‚ö†Ô∏è  Original sequence not found for base: {base}\")\n",
    "        continue\n",
    "\n",
    "    for feat in chem_cols:\n",
    "        if feat not in df1.columns or pd.isna(original_row[feat].values[0]):\n",
    "            continue\n",
    "\n",
    "        if not pd.api.types.is_numeric_dtype(df1[feat]):\n",
    "            print(f\"Skipping non-numeric feature: {feat}\")\n",
    "            continue\n",
    "\n",
    "        original_value = original_row[feat].values[0]\n",
    "        lower_bound = original_value * 0.93\n",
    "        upper_bound = original_value * 1.07\n",
    "\n",
    "        filtered_df = base_df[\n",
    "            ((base_df[feat] < lower_bound) | (base_df[feat] > upper_bound)) |\n",
    "            (base_df['Sequence_ID'] == original_id)\n",
    "        ].dropna(subset=[feat, 'log2FoldChange', 'lfcSE'])\n",
    "\n",
    "        if len(filtered_df) < min_n:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {base} - {feat}: n={len(filtered_df)} < {min_n}\")\n",
    "            continue\n",
    "\n",
    "        r_vals = []\n",
    "        slope_vals = []\n",
    "        for _ in range(n_iter):\n",
    "            sample = filtered_df.sample(frac=1, replace=True, random_state=rng.integers(1e9))\n",
    "            if sample[feat].nunique() > 1 and sample['log2FoldChange'].nunique() > 1:\n",
    "                r = sample[feat].corr(sample['log2FoldChange'], method='spearman')\n",
    "                if pd.notnull(r):\n",
    "                    r_vals.append(r)\n",
    "                slope, _, _, _, _ = stats.linregress(sample[feat], sample['log2FoldChange'])\n",
    "                if pd.notnull(slope):\n",
    "                    slope_vals.append(slope)\n",
    "\n",
    "        if r_vals:\n",
    "            r_full, p_full = stats.spearmanr(filtered_df[feat], filtered_df['log2FoldChange'])\n",
    "            r_array = np.array(r_vals)\n",
    "            bootstrap_p = 2 * min(np.mean(r_array > 0), np.mean(r_array < 0))\n",
    "            bootstrap_p = max(bootstrap_p, 1/n_iter)\n",
    "            \n",
    "            results.append({\n",
    "                'base_origin': base,\n",
    "                'feature': feat,\n",
    "                'r_mean': np.mean(r_vals),\n",
    "                'r_std': np.std(r_vals),\n",
    "                'slope_mean': np.mean(slope_vals) if slope_vals else np.nan,\n",
    "                'slope_std': np.std(slope_vals) if slope_vals else np.nan,\n",
    "                'p_value': p_full,\n",
    "                'bootstrap_p': bootstrap_p,\n",
    "                'n_samples': len(filtered_df),\n",
    "                'mean_lfcSE': filtered_df['lfcSE'].mean()\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 6: Apply FDR correction and save results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "_, pvals_adj, _, _ = multipletests(results_df['p_value'], method='fdr_bh')\n",
    "results_df['p_adj'] = pvals_adj\n",
    "results_df['neg_log10_padj'] = -np.log10(results_df['p_adj'].clip(lower=1e-300))\n",
    "\n",
    "_, bootstrap_pvals_adj, _, _ = multipletests(results_df['bootstrap_p'], method='fdr_bh')\n",
    "results_df['bootstrap_p_adj'] = bootstrap_pvals_adj\n",
    "results_df['neg_log10_bootstrap_padj'] = -np.log10(results_df['bootstrap_p_adj'].clip(lower=1e-300))\n",
    "\n",
    "results_df.to_csv('spearman_2zn_results.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Total correlations calculated: {len(results_df)}\")\n",
    "print(f\"Significant (p_adj < 0.05): {(results_df['p_adj'] < 0.05).sum()}\")\n",
    "print(f\"Sample size statistics:\")\n",
    "print(results_df['n_samples'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 7: Create clustered heatmap ===\n",
    "heatmap_df = results_df.pivot(index='feature', columns='base_origin', values='r_mean')\n",
    "heatmap_df = heatmap_df[custom_origin_order]\n",
    "heatmap_df_clean = heatmap_df.dropna(how='all')\n",
    "heatmap_df_transposed = heatmap_df_clean.T\n",
    "heatmap_df_for_clustering = heatmap_df_transposed.fillna(0)\n",
    "\n",
    "fig_width = len(heatmap_df_clean)*0.6 + 6\n",
    "fig_height = len(custom_origin_order)*0.7 + 4\n",
    "\n",
    "g = sns.clustermap(\n",
    "    heatmap_df_for_clustering,\n",
    "    cmap='coolwarm',\n",
    "    center=0, vmin=-1, vmax=1,\n",
    "    figsize=(fig_width, fig_height),\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Mean Spearman r'},\n",
    "    annot=True, fmt=\".2f\",\n",
    "    method='average', metric='euclidean',\n",
    "    row_cluster=True, col_cluster=True,\n",
    "    dendrogram_ratio=0.15,\n",
    "    cbar_pos=(0.92, 0.3, 0.03, 0.4)\n",
    ")\n",
    "\n",
    "g.fig.suptitle(f'{round_name}: Spearman r (Filtered ¬±7%, n‚â•{min_n})', fontsize=14, y=1.02)\n",
    "g.ax_heatmap.set_xlabel('Feature', fontsize=12)\n",
    "g.ax_heatmap.yaxis.set_ticks_position('right')\n",
    "g.ax_heatmap.yaxis.set_label_position('right')\n",
    "g.ax_heatmap.set_ylabel('base_origin', fontsize=12)\n",
    "\n",
    "clustered_row_order = g.dendrogram_row.reordered_ind\n",
    "clustered_col_order = g.dendrogram_col.reordered_ind\n",
    "row_labels = heatmap_df_for_clustering.index[clustered_row_order]\n",
    "col_labels = heatmap_df_for_clustering.columns[clustered_col_order]\n",
    "\n",
    "plt.savefig('spearman_2zn_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# === Step 7b: Slope/Amplitude Heatmap ===\n",
    "print(\"\\nüìä Creating slope heatmap...\")\n",
    "magenta_white_green = LinearSegmentedColormap.from_list('magenta_white_green', ['magenta', 'white', 'green'])\n",
    "\n",
    "slope_heatmap = results_df.pivot(index='feature', columns='base_origin', values='slope_mean')\n",
    "slope_heatmap_T = slope_heatmap.T.fillna(0)\n",
    "slope_heatmap_ordered = slope_heatmap_T.reindex(index=row_labels, columns=col_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "sns.heatmap(slope_heatmap_ordered, cmap=magenta_white_green, center=0, vmin=-3, vmax=3,\n",
    "            linewidths=0.5, cbar_kws={'label': 'Slope (Amplitude)'}, annot=True, fmt=\".1f\", ax=ax)\n",
    "ax.set_title(f'{round_name}: Slope/Amplitude (Filtered ¬±7%, n‚â•{min_n})', fontsize=14)\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.yaxis.set_ticks_position('right')\n",
    "ax.yaxis.set_label_position('right')\n",
    "ax.set_ylabel('base_origin', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('slope_amplitude_2zn_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# === Step 7c: Analytic P-value Heatmap ===\n",
    "print(\"\\nüìä Creating analytic p-value heatmap...\")\n",
    "white_to_purple = LinearSegmentedColormap.from_list('white_purple', ['white', 'mediumpurple', 'darkviolet', 'indigo'])\n",
    "sig_threshold = -np.log10(0.05)\n",
    "\n",
    "pval_heatmap = results_df.pivot(index='feature', columns='base_origin', values='neg_log10_padj')\n",
    "pval_heatmap_T = pval_heatmap.T.fillna(0)\n",
    "pval_heatmap_ordered = pval_heatmap_T.reindex(index=row_labels, columns=col_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "sns.heatmap(pval_heatmap_ordered, cmap=white_to_purple, vmin=0, vmax=max(pval_heatmap_ordered.values.max(), 5),\n",
    "            linewidths=0.5, cbar_kws={'label': '-log10(adj p-value)'}, annot=True, fmt=\".1f\", ax=ax)\n",
    "ax.set_title(f'{round_name}: Analytic Confidence -log10(FDR adj p)\\n(values > {sig_threshold:.1f} are significant)', fontsize=14)\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.yaxis.set_ticks_position('right')\n",
    "ax.yaxis.set_label_position('right')\n",
    "ax.set_ylabel('base_origin', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confidence_pvalue_2zn_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# === Step 7d: r_std Heatmap (Bootstrap Uncertainty) ===\n",
    "print(\"\\nüìä Creating r_std (bootstrap uncertainty) heatmap...\")\n",
    "white_to_red = LinearSegmentedColormap.from_list('white_red', ['white', 'lightsalmon', 'red', 'darkred'])\n",
    "\n",
    "rstd_heatmap = results_df.pivot(index='feature', columns='base_origin', values='r_std')\n",
    "rstd_heatmap_T = rstd_heatmap.T.fillna(0)\n",
    "rstd_heatmap_ordered = rstd_heatmap_T.reindex(index=row_labels, columns=col_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "sns.heatmap(rstd_heatmap_ordered, cmap=white_to_red, vmin=0, vmax=0.3,\n",
    "            linewidths=0.5, cbar_kws={'label': 'r_std (Bootstrap SD)'}, annot=True, fmt=\".2f\", ax=ax)\n",
    "ax.set_title(f'{round_name}: Bootstrap Uncertainty (r_std)\\n(lower = more stable)', fontsize=14)\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.yaxis.set_ticks_position('right')\n",
    "ax.yaxis.set_label_position('right')\n",
    "ax.set_ylabel('base_origin', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rstd_uncertainty_2zn_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# === Step 7e: Bootstrap Confidence Heatmap ===\n",
    "print(\"\\nüìä Creating bootstrap confidence heatmap...\")\n",
    "white_to_teal = LinearSegmentedColormap.from_list('white_teal', ['white', 'lightseagreen', 'teal', 'darkslategray'])\n",
    "\n",
    "bootstrap_pval_heatmap = results_df.pivot(index='feature', columns='base_origin', values='neg_log10_bootstrap_padj')\n",
    "bootstrap_pval_heatmap_T = bootstrap_pval_heatmap.T.fillna(0)\n",
    "bootstrap_pval_heatmap_ordered = bootstrap_pval_heatmap_T.reindex(index=row_labels, columns=col_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "sns.heatmap(bootstrap_pval_heatmap_ordered, cmap=white_to_teal, vmin=0, vmax=max(bootstrap_pval_heatmap_ordered.values.max(), 5),\n",
    "            linewidths=0.5, cbar_kws={'label': '-log10(adj bootstrap p)'}, annot=True, fmt=\".1f\", ax=ax)\n",
    "ax.set_title(f'{round_name}: Bootstrap Confidence -log10(FDR adj p)\\n(values > {sig_threshold:.1f} are significant)', fontsize=14)\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.yaxis.set_ticks_position('right')\n",
    "ax.yaxis.set_label_position('right')\n",
    "ax.set_ylabel('base_origin', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('bootstrap_confidence_2zn_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Generated 5 heatmaps: correlation, slope, analytic p-value, r_std, and bootstrap p-value\")\n",
    "\n",
    "# === Step 8: Plot significant scatterplots (|r| >= 0.6) ===\n",
    "print(f\"\\nüìà Plotting correlations with |r| >= 0.6...\")\n",
    "plot_count = 0\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    if abs(row['r_mean']) >= 0.6:\n",
    "        base = row['base_origin']\n",
    "        feat = row['feature']\n",
    "        original_id = f\"original_sequence_-_{base}\"\n",
    "        original_row = df1[df1['Sequence_ID'] == original_id]\n",
    "\n",
    "        if original_row.empty or pd.isna(original_row[feat].values[0]):\n",
    "            continue\n",
    "\n",
    "        original_value = original_row[feat].values[0]\n",
    "        lower_bound = original_value * 0.93\n",
    "        upper_bound = original_value * 1.07\n",
    "\n",
    "        plot_df = df1[\n",
    "            (df1['base_origin'] == base) &\n",
    "            ((df1['Sequence_ID'] == original_id) | \n",
    "             ((df1[feat] < lower_bound) | (df1[feat] > upper_bound)))\n",
    "        ].dropna(subset=[feat, 'log2FoldChange', 'lfcSE'])\n",
    "\n",
    "        if plot_df.shape[0] < min_n:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.errorbar(plot_df[feat], plot_df['log2FoldChange'], yerr=plot_df['lfcSE'], \n",
    "                     fmt='o', alpha=0.6, ecolor='gray', elinewidth=1, capsize=2, label='Variants')\n",
    "\n",
    "        if not original_row.empty:\n",
    "            wt_se = original_row['lfcSE'].values[0] if pd.notna(original_row['lfcSE'].values[0]) else 0\n",
    "            plt.errorbar(original_row[feat], original_row['log2FoldChange'], yerr=wt_se, \n",
    "                         fmt='o', color='red', markersize=8, label='WT')\n",
    "\n",
    "        sns.regplot(x=feat, y='log2FoldChange', data=plot_df, scatter=False, ci=95, \n",
    "                    color='blue', line_kws={'label': 'Fit'})\n",
    "\n",
    "        plt.xlabel(feat)\n",
    "        plt.ylabel('log2FoldChange')\n",
    "        plt.title(f'{base}: {feat} vs log2FoldChange\\n(r={row[\"r_mean\"]:.2f}, n={row[\"n_samples\"]})')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'scatter_{base}_{feat}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plot_count += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {plot_count} scatter plots for correlations with |r| >= 0.6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
